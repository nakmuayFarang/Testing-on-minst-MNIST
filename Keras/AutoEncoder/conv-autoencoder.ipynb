{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "(xtr,_),(xtest,ytest) = mnist.load_data()\n",
    "\n",
    "xtr = xtr.reshape((-1,28,28,1)).astype('float32')/255\n",
    "xtest = xtest.reshape((-1,28,28,1)).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layers import \n",
    "from tensorflow.keras.layers import Dense, Flatten,Reshape, Conv2D,Conv2DTranspose, Input\n",
    "from tensorflow.keras.backend import int_shape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "latentSize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "latent_space (Dense)         (None, 16)                802832    \n",
      "=================================================================\n",
      "Total params: 826,128\n",
      "Trainable params: 826,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=xtr[0].shape, name='Input_layer' )\n",
    "\n",
    "x = Conv2D(kernel_size=3,filters=16,strides=1,padding='same')(inputs)\n",
    "x = Conv2D(kernel_size=3,filters=32,strides=1,padding='same')(x)\n",
    "x = Conv2D(kernel_size=3,filters=64,strides=1,padding='same')(x)\n",
    "\n",
    "shp = int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "out = Dense(latentSize,name=\"latent_space\")(x)\n",
    "\n",
    "encoder = Model(inputs,out, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "latent_space_in (InputLayer) [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50176)             852992    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 913,153\n",
      "Trainable params: 913,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latentSpace = Input(shape=latentSize,name=\"latent_space_in\" )\n",
    "\n",
    "x = Dense(shp[1]*shp[2]*shp[3])(latentSpace)\n",
    "x = Reshape((shp[1],shp[2],shp[3]))(x)\n",
    "\n",
    "x = Conv2DTranspose(kernel_size=3,filters=64,strides=1,padding='same')(x)\n",
    "x = Conv2DTranspose(kernel_size=3,filters=32,strides=1,padding='same')(x)\n",
    "x = Conv2DTranspose(kernel_size=3,filters=16,strides=1,padding='same')(x)\n",
    "\n",
    "outputs = Conv2DTranspose(kernel_size=3,filters=1,strides=1,padding='same')(x)\n",
    "\n",
    "\n",
    "decoder = Model(latentSpace,outputs,name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                826128    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         913153    \n",
      "=================================================================\n",
      "Total params: 1,739,281\n",
      "Trainable params: 1,739,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output = decoder(encoder(inputs))\n",
    "autoencoder = Model(inputs,output,name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mse',optimizer='adam',metric=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 31s 510us/sample - loss: 0.0441 - val_loss: 0.0286\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 25s 423us/sample - loss: 0.0283 - val_loss: 0.0273\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 25s 423us/sample - loss: 0.0276 - val_loss: 0.0271\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 25s 423us/sample - loss: 0.0276 - val_loss: 0.0271\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 0.0276 - val_loss: 0.0271\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 25s 423us/sample - loss: 0.0275 - val_loss: 0.0271\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 26s 427us/sample - loss: 0.0275 - val_loss: 0.0270\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 26s 426us/sample - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 26s 428us/sample - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 26s 431us/sample - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 26s 428us/sample - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.0274 - val_loss: 0.0269\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 26s 431us/sample - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 26s 432us/sample - loss: 0.0274 - val_loss: 0.0269\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 26s 430us/sample - loss: 0.0274 - val_loss: 0.0273\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 26s 433us/sample - loss: 0.0274 - val_loss: 0.0269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc99839b88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x=xtr,y=xtr,validation_data=[xtest,xtest],epochs=20,batch_size=1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
